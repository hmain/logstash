input {

# Use file input as S3 input doesn't work in logstash 1.3.3
# See the file s3-to-logstash.sh for a simple bash-script that pulls from s3 and unpacks the logs so that logstash can understand them.

    file {
      path => [ '/path/to/cloudfront/logs/*' ]
      type => [ 'cloudfront' ]
    }
}


filter {

# Ignore all commented lines
 if [message] =~ /^#/ {
    drop { }
  }

 if [type] == 'cloudfront' {
      csv {
        'columns' => [ 'date', 'time', 'x-edge-location', 'sc-bytes', 'c-ip', 'cs-method', 'cs(Host)', 'cs-uri-stem', 'sc-status', 'cs(Referer)', 'cs(User-Agent)', 'cs-uri-query', 'cs(Cookie)', 'x-edge-result-type', 'x-edge-request-id', 'x-host-header', 'cs-protocol', 'cs-bytes' ]
        'separator' => '	'
        # Add a field where timestamp is created from two columns
        'add_field' => [ 'cf_timestamp', '%{date} %{time}' ]
      }
      date {
         'match' => [ 'cf_timestamp', 'yy-MM-dd HH:mm:ss' ]
      }
    }
}


output {
  elasticsearch { embedded => true }
}
